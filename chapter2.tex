\chapter{Tensor Structured Coupled Cluster}
\label{ch:tcc} 
The discussion presented in this section based on our published work, see 
Ref.~\cite{schutski2017tensor}, and also on new results intended for another 
publication.

\section{Motivation}
\label{sec:Introduction} 
Having seen that both strong and weak electronic correlation can be captured 
by methods based on the Projected Hartree-Fock, let us now turn to another 
powerful family of theories to solve many-body problems, namely, Coupled 
Cluster (CC). Since their introduction in the nuclear 
physics,\cite{coester1958bound, coester1960short} Coupled Cluster methods 
quickly became a "gold standard" of quantum chemistry due to their exceptional 
ability to capture weak electronic correlation, while having polynomial 
computational cost in basis size. Another attractive properties of most CC 
methods are size consistency and size extensivity.\cite{pople1978electron, 
bartlett1978many, crawford2000introduction, bartlett2007coupled} 

{\color{red} Insert 2 paragraphs here where accuracy of Coupled Cluster is 
discussed. Take it from Irek.}

Coupled Cluster methods parameterize the solution in terms of a reference 
wavefunction $| 0 \rangle$ and a set of excitation operators:
\begin{equation}
 | \phi \rangle  = \exp({}^1\hat{T} + {}^2\hat{T} + {}^3\hat{T} + \ldots) | 0 
\rangle
\end{equation}
where ${}^1\hat{T}, {}^2\hat{T}, \ldots$ are appropriate single, double, and 
higher order excitations from the reference state $| 0 \rangle$ (usually a HF 
solution). The method with n-body excitations is exact for n-electron systems. 
In practice, however, the excitation operator is truncated at doubles due to 
high computational cost, leading to Coupled Cluster with Singles and Doubles 
methods (CCSD).\cite{purvis1982full} Higher order excitations can be included 
approximately with the help of perturbation theory, such as in the highly 
accurate and widely used Coupled Cluster with Singles, Doubles and 
perturbative Triples (CCSD(T)) approach.\cite{bartlett1990non}

CC methods are also distinguished by the form of excitation operators, 
leading to Restricted (RCCSD),\cite{scuseria_ccsd} Unrestricted (UCCSD) and 
General (GCCSD) Coupled Cluster, in the same way as Hartree-Fock methods can be 
classified. A further analogy to HF method is that the solution of conventional 
Restricted Coupled Cluster method has proper $S^{2}$ and $S^{z}$ symmetry, but a 
wrong energy in case of strong correlation.

\begin{figure}[!ht]
\centering
 \rule{0.8\textwidth}{2cm}
 \caption{Restricted Coupled Cluster with Singles and Doubles in different 
correlation regimes. System: $N_{2}$, cc-pVDZ basis set. Exact is FCI solution.}
\end{figure}

This failure of Restricted CCSD in strong correlation regime is one (and 
probably most serious) downside of traditional Coupled Cluster theory. Another 
drawback is a steep growth of computational cost,\cite{noga1987full, 
scuseria1989coupled} which scales as $O(N^6)$ for CCSD, $O(N^7)$ for CCSD(T), 
and $O(N^8)$ for CCSDT, where $N$ is a size of basis. In the following we set 
to tackle both of these problems of conventional Coupled Cluster theory with 
tensor decompositions.

\section{Restricted Coupled Cluster with Singles and Doubles}
Let us start by describing the traditional Restricted Coupled Cluster 
\emph{ansatz}.\cite{bartlett2007coupled} The wavefunction is 
parameterized by an excitation operator $T$ and a single reference 
determinant $| 0 \rangle$:

\begin{equation}
 | \phi \rangle  = \exp(\hat{T}) | 0 \rangle = \exp({}^1\hat{T} + {}^2\hat{T} + 
{}^3\hat{T} + \ldots) | 0 \rangle
\end{equation}

In restricted version of Coupled Cluster theory excitation operators are spin 
adapted combinations of creation and annihilation operators of the form:

\begin{equation}
\begin{split}
 E_{i}^{a} & = \frac{1}{2} \cdot (a_{a, \uparrow}^{\dagger} a_{i, \uparrow} + 
a_{a, \downarrow}^{\dagger} a_{i, \downarrow}) \\
 {}^{1}\hat{T} & = {}^{1}T_{i}^{a} E_{i}^{a} \\
 {}^{2}\hat{T} & = \frac{1}{2} ~~ {}^{2}T_{ij}^{ab} E_{i}^{a} E_{j}^{b} \\
 \ldots
\end{split}
\end{equation}

Here indices $i, j$ represent particles, $a, b$ represent holes and summation 
is implied over repeated indices. The quantities denoted by $T$ are 
excitation amplitude tensors, e. g. two, four or higher dimensional arrays of 
numbers.

The excitation operator is truncated to a specific level, the most widely used 
choice being doubles, e. g. ${}^{2}\hat{T}$, leading to RCCSD model. If singles 
are omitted as well, we end up with RCCD method. With a wavefunction in the 
chosen form the Schr{\"o}edinger equation is

\begin{equation}
 H \exp(\hat{T}) |0 \rangle = E \exp(\hat{T}) |0 \rangle
\end{equation}

This equation is usually solved projectively by multiplying both sides of the 
expression by $\exp(-\hat{T})$. 
\begin{equation}
 \exp(-\hat{T}) H \exp(\hat{T)} | 0 \rangle = \bar{H} | 0 \rangle = E | 0 
\rangle
\label{eq:cc_lhs}
\end{equation}

From equation \ref{eq:cc_lhs} the energy can be extracted as an expectation 
value of the transformed Hamiltonian $\bar{H}$:

\begin{equation}
 E = \langle 0 | \bar{H} | 0 \rangle
\end{equation}

To obtain excitation amplitudes, the similarity transformed Hamiltonian 
is projected onto the set of excited determinants on the left.
Denoting these determinants as $\langle {}^{1}Z |$, $\langle {}^{2}Z|$
for single, double etc. excitations, one comes to a set of equations

\begin{equation}
\begin{cases}
 \langle {}^{1} Z_{i}^{a} | \bar{H} | 0 \rangle = {}^{1}R_{i}^{a} = 0 \\
 \langle {}^{2} Z_{ij}^{ab} | \bar{H} | 0 \rangle = {}^{2}R_{ij}^{ab} = 0 \\
 \ldots
\end{cases}
\label{eq:cc_residuals}
\end{equation}

where for every excited determinant the corresponding value of the residuals 
$R$ is zero. Residual equations are polynomial in the excitation amplitude 
tensors ${}^{1}T_{i}^{a}$, ${}^{2}T_{ij}^{ab}$ etc.

A common way of solving Eqn. \ref{eq:cc_residuals} is to split residual 
expressions into left and right hand sides to extract amplitudes. One such 
splitting is
\begin{subequations}
\begin{align}
 {}^{1}T_{i}^{a} &= {}^{1}D_{i}^{a} ~ {}^{1}G_{i}^{a}({}^{1}T, {}^{2}T), \\
{}^{2}T_{ij}^{ab} &= {}^{2}D_{ij}^{ab} ~ {}^{2}G_{ij}^{ab}({}^{1}T, {}^{2}T), 
\label{eq:cc_amplitude_equations_b}
\end{align}
\label{eq:cc_amplitude_equations}
\end{subequations}
Here, ${}^1D$ and ${}^2D$ are orbital energy
denominator tensors constructed from diagonal elements of the Fock matrix
$F$:

\begin{subequations}
\begin{align} {}^1D_i^a &= \frac{1}{F_a^a - F_i^a}, \\
{}^{2}D_{ij}^{ab} &= \frac{1}{F_{a}^{a} + F_{b}^{b} - F_{i}^{i} -
F_{j}^{j}}.
\end{align}
\label{eq:cc_denom_definition}
\end{subequations} 

Amplitude equations \ref{eq:cc_amplitude_equations} are solved by iterations 
until a fixed point is found.

Solving amplitude equations is computationally demanding, and determines a 
very steep cost of CC approach. For example, the evaluation of 
the right hand side of Eq. \ref{eq:cc_amplitude_equations_b} requires 
$O(N^6)$ summations and multiplications per iteration, hence RCCSD method has 
$O(N^6)$ cost. The root of this problem is the need to manipulate high order 
tensors representing the Hamiltonian and excitation amplitudes. This problem, 
however, can be circumvented by using novel techniques of tensor 
decompositions coming from multilinear algebra,\cite{kolda2009tensor} as we 
will show. 

\section{Tensor Contractions and the Cost of Coupled Cluster}
Let us discuss the cost of Coupled Cluster methods. The amplitude update 
equation in RCCD, the simplest representative of CC family, is:

\begin{equation}
\begin{split}
T^{ab}_{ij} & = D^{ab}_{ij} \cdot (- V^{ab}_{ij} \\
& + \sum_{k \neq i} F^{k}_{i} T^{ab}_{kj}
+  \sum_{k \neq j} F^{k}_{j}  T^{ab}_{ik}
- \sum_{c \neq a} F^{a}_{c}  T^{bc}_{ji}
- \sum_{c \neq b} F^{b}_{c}  T^{ac}_{ij} \\
& - T^{cd}_{ij}  V^{ab}_{cd}
+ T^{ac}_{ik}  V^{bk}_{cj} 
+ T^{ac}_{ki}  V^{bk}_{jc} 
+ T^{ac}_{kj}  V^{bk}_{ci} 
+ T^{bc}_{jk}  V^{ak}_{ci}\\
&+ T^{bc}_{ki}  V^{ak}_{cj} 
+ T^{bc}_{kj}  V^{ak}_{ic}
- 2 T^{ac}_{ik}  V^{bk}_{jc}
- 2 T^{bc}_{jk}  V^{ak}_{ic}
- T^{ab}_{kl}  V^{kl}_{ij} \\
&- T^{ab}_{ik}  T^{cd}_{lj}  V^{kl}_{cd} 
- T^{ab}_{kj}  T^{cd}_{il} V^{kl}_{dc}
- T^{ab}_{kl}  T^{cd}_{ij} V^{kl}_{cd}
- T^{ac}_{ij}  T^{bd}_{kl}  V^{kl}_{dc}
-  T^{ac}_{ik}  T^{bd}_{lj} V^{kl}_{dc} \\
&- T^{ac}_{ki}  T^{bd}_{jl} V^{kl}_{dc}
- T^{ac}_{ki}  T^{bd}_{lj} V^{kl}_{cd}
- T^{ac}_{kj}  T^{bd}_{li} V^{kl}_{dc}
-  T^{ac}_{kl}  T^{bd}_{ji} V^{kl}_{cd}
+ 2    T^{ab}_{ik} T^{cd}_{lj}  V^{kl}_{dc}\\
&+ 2    T^{ab}_{kj} T^{cd}_{il}  V^{kl}_{cd}
+ 2    T^{ac}_{ij} T^{bd}_{kl}  V^{kl}_{cd}
+ 2    T^{ac}_{ik}  T^{bd}_{jl}  V^{kl}_{dc}
+ 2    T^{ac}_{ik}  T^{bd}_{lj}  V^{kl}_{cd}  
+ 2    T^{ac}_{ki} T^{bd}_{jl}  V^{kl}_{cd}\\
&+ 2    T^{ac}_{kl} T^{bd}_{ji}  V^{kl}_{dc}
- 4    T^{ac}_{ik} T^{bd}_{jl}  V^{kl}_{cd})
\end{split}
\label{eq:ccd_amplitude_equation}
\end{equation}

Here $V$ is electron interaction tensor in the molecular orbital basis (Dirac 
ordered), $F$ is a Fock matrix, and $D$ is an orbital energy denominator. Most 
of the terms on the right hand side of Eqn.~\ref{eq:ccd_amplitude_equation} are 
numerically expensive to evaluate. For example, the sixth 
contraction in Eqn.~\ref{eq:ccd_amplitude_equation} is
\begin{equation}
 \tau^{ab}_{ij} = T^{ac}_{ik}  V^{bk}_{cj}
 \label{eq:ccd_intermediate_example}
\end{equation}
This expression requires $O(N^6)$ multiplications and additions, as for every 
of $N^4$ elements in the intermediate $\tau$ one has to calculate $N^2$ products
and sums. To facilitate the discussion and the estimates of cost let us 
introduce a graphical notation for tensors:

\begin{equation}
\vcenter{\hbox{\includegraphics[width=0.6\textwidth]{figures/cc_contraction_1}}}
.
\label{fig:cc_contraction_1}
\end{equation}

In the graphical notation we represent tensors by shapes, and their indices by 
lines. Open lines mean free indices, and connected lines denote contraction 
over respective indices. One can then estimate the cost of the contraction as 
$N$ to the power of the number of connected lines plus the number of 
open lines if each index had a size proportional to $N$. The cost scales 
as $N^6$ in this example. For more examples of this notation please see the 
Appendix~\ref{sec:Appendix}. We will omit index letters on further diagrams.

The very same contraction can be done with lesser effort if electron 
interaction tensor is approximated by a well known\cite{beebe1977, 
vahtras1993integral, boman2008method, sierka2003fast} Resolution of Identity 
(RI) decomposition, also known as Density Fitting (DF):
%
\begin{equation} V^{pq}_{rs} \approx \sum_{\alpha \alpha^{\prime}} 
U_{pr}^{\alpha}
D_{\alpha,\alpha^{\prime}} \tilde{U}_{qs}^{\alpha^{\prime}},
\label{eq:ri_decomposition}
\end{equation}
Here $U$ and $\tilde{U}$ are three index integrals and $D$ is a generalized 
overlap.\cite{ahmadi1995coulomb}. It is well known that the 
error of this approximation decreases exponentially with the 
size of auxiliary basis $\{ \alpha \}$, called the rank of RI, and that 
negligible errors are attained 
with $dim(\{ \alpha \}) = r_{RI} = O(N)$.\cite{beebe1977, sierka2003fast} 
Diagrammatically, Eqn.~\ref{eq:ri_decomposition} is

\begin{equation}
\vcenter{\hbox{\includegraphics[width=0.6\textwidth]{figures/ri_decomposition}}}
.
\label{fig:ri_decomposition}
\end{equation}

By using the RI approximation to the electron interaction tensor the 
intermediate in Eqn.~\ref{fig:cc_contraction_1} can be formed at $O(N^5)$ cost, 
as shown on the diagram below:

\begin{equation}
\vcenter{\hbox{\includegraphics[width=0.6\textwidth]{figures/cc_contraction_2}}}
.
\label{fig:cc_contraction_2}
\end{equation}

The RI decomposition has been used for a long time to reduce the
scaling of quantum chemistry algorithms, for example, in the RI-MP2
method.\cite{ayala1999linear, werner2003fast, izmaylov2008resolution} An 
important caveat is that, however, keeping the dimension of the auxiliary 
basis low, in this approximation one can only 
separate a pair of indices $p, r$ 
from another pair $q, s$ with negligible error, but not $p, q$ from $r, s$. 
In the latter case the rank of RI has to be $r_{RI} = O(N^2)$ instead of 
$r_{RI} = O(N)$ in the former case to provide equivalent error, and thus such 
approximation would be not useful. Those properties of RI are 
apparent from the form of the electron interaction operator:

\begin{equation}
%\begin{split}
 V^{pq}_{rs} = \int \frac{\phi^{\ast}_{p}(r_{1}) 
\phi^{\ast}_{q}(r_{2}) \phi_{r}(r_{1}) \phi_{s}(r_{2})}{| r_{1} - r_{2} |} 
dr_{1} dr_{2} \\ 
%& \approx \int \phi^{\ast}_{p}(r_{1}) \phi_{r}(r_{1}) \chi_{\alpha}(r_{1}) 
%dr_{1} 
%\int \phi^{\ast}_{q}(r_{2}) \chi_{s}(r_{2}) \psi_{\alpha^{\prime}}(r_{2}) 
%dr_{2} \\ & \cdot \int \frac{\chi_{\alpha}(r_{1}) 
%\chi_{\alpha^{\prime}}(r_{2})}{| r_{1} - 
%r_{2} |} dr_{1} dr_{2}
%\end{split}
\label{eq:ri_decomposition_integral}
\end{equation}
As Eqn.~\ref{eq:ri_decomposition_integral} shows a separation of variables 
between a pair of basis functions $p, r$ and $q, s$ is possible when the 
distance $|r_{1} - r_{2}|$ is large. In contrast, this is not true for pairs 
$p, q$ and $r, s$.

This limitation of RI decomposition does not allow cost reduction during the 
calculation of several terms in the ${}^{2}T$ equation of RCCD. For example, 
the evaluation of the intermediate of the form:
\begin{equation}
 \tau^{ab}_{ij} = - T^{cd}_{ij}  V^{ab}_{cd}
 \label{eq:ccd_intermediate_example2}
\end{equation}
does not benefit from RI decomposition of $V$.
\begin{equation}
\vcenter{\hbox{\includegraphics[width=0.8\textwidth]{figures/cc_contraction_3}}}
.
\end{equation}
Further approximations, however, can lead to reduced scaling, as we will show 
later.

\section{Tensor decompositions}
As was noted before, simple RI approximation may not always be flexible enough 
to reduce the computational cost of tensor contractions. To build a more 
applicable approximation of the interaction tensor we need to consider 
additional tensor decompositions. In this section we would only briefly list 
the decompositions we used, and refer the reader to original publications for 
technical details. The important information here is the structure of the 
described factorizations, which we demonstrate using tensor diagrams. Another 
important aspect is the alternating least squares method (ALS), as it can be 
used to calculate \emph{any} of the described decompositions and is a 
cornerstone of our factorized CC approaches.


\subsection{Canonical Polyadic Decomposition}
The canonical polyadic decomposition (CPD) of a tensor is a decomposition of 
the form:\cite{de2006link}
%
\begin{equation}
T_{pqr\ldots} = \sum_\alpha a_p^\alpha \, b_q^\alpha \,
c_r^\alpha \ldots
\label{eq:cpd_definition}
\end{equation}

The dimension of the auxiliary index $\alpha$ is called the rank of the 
decomposition. The CPD of a three index tensor is shown below diagrammatically.
\begin{equation}
\vcenter{\hbox{\includegraphics[width=0.4\textwidth]{figures/cp_decomposition}}}
.
\label{fig:cp_decomposition}
\end{equation}
%
This factorization can be seen as one of the generalizations of classic 
decompositions of matrices, such as QR, LU or Singular Value Decomposition, to 
higher order tensors.\cite{kolda2009tensor} The important difference, is, 
however, that no closed form algorithm to extract the CPD for generic tensors 
is known, and one has to rely on iterative optimization techniques to calculate 
the CP decomposition.\cite{sorber2013optimization} 

Substantial effort has been made by the mathematical community to develop 
optimization techniques for CPD. We refer the 
reader to the corresponding reviews\cite{kolda2009tensor, 
sidiropoulos2016tensor} for further details. Typical algorithms are the 
alternating least squares (ALS),\cite{comon2009tensor} gradient descent by 
means of the method of Broyden, Fletcher, Goldfarb, and Shanno 
(BFGS), and nonlinear least squares (NLS) methods.\cite{sorber2013optimization}

For a limited number of special tensors their CPD can be built analytically. 
One such case are denominator tensors in the CC methods (see Eqn. 
\ref{eq:cc_denom_definition}), which have the form
\begin{equation}
D^{ab\ldots}_{ij\ldots} = 
\frac{1}{F_{a}^{a} + F_{b}^{b} + \ldots - F_{i}^{i} - 
F_{j}^{j} - \ldots}
\end{equation}
CP decomposition of denominator tensors can be built using an exponential
parameterization\cite{braess2005approximation} (which was known as Laplace
transformation in quantum chemistry for a long 
time\cite{almlof1991elimination}) as, for example,
%
\begin{subequations}
\begin{align} {}^2D_{ij}^{ab} &= 
\sum_{\omega} C_\omega \, \mathrm{e}^{A_\omega \,
F_i^i} \, \mathrm{e}^{A_\omega \, F_j^j} \, \mathrm{e}^{-A_\omega \,
F_a^a} \, \mathrm{e}^{-A_\omega \, F_b^b} \\ &= \sum_{\omega} {}^2D^1_{i,\omega} 
\,
{}^2D^2_{j,\omega} \, {}^2D^3_{a,\omega} \, {}^2D^4_{b,\omega}.
\end{align}
\end{subequations}
%
Quadrature weights $C_{w}$ and coefficients $A_{w}$ in this case can be 
precomputed without the knowledge of the actual values of the Fock matrix $F$, 
and provide very high accuracy of the CPD.\cite{braess2005approximation}

Another important special case are very sparse tensors. A tensor $T$ having $r$
non zero elements can be represented exactly by its trivial CPD of rank $r$, 
which will take a form
\begin{equation}
T_{pqr\ldots} = \sum_{\alpha \in T_{pqr\ldots} \neq 0} T_{p^\alpha q^{\alpha} 
r^{\alpha}\ldots} \cdot e^{1}_{p^{\alpha}} \, e^{2}_{q^\alpha} \, 
e^{3}_{r^\alpha} \ldots
\label{eq:trivial_cpd_dec}
\end{equation}
where $e^{n}_{p^{\alpha}}$ is a unit vector of the length of $n$-th dimension 
of $T$ having $1$ in $p^{\alpha}$-th position, and $T_{pqr\ldots}$ is the non 
zero element of $T$. Essentially, CPD in this case is a sum of rank-1 tensors 
having $1$ in a specific entry and zeros everywhere else multiplied by the 
value of the corresponding entry in $T$. This trivial decomposition may be 
useful only if the number of non zero entries of $T$, and hence the rank of the 
CPD, is small. However, it shows an intrinsic connection of the CPD and 
sparsity.

\subsection{Tensor Hyper Contraction}
\label{sec:tensor_hypercontraction}
The resolution of identity, which we considered before, can be combined with 
the canonical decomposition. Indeed, if three-index tensors in RI are further 
approximated by CPD one comes to a Tensor Hypercontraction introduced by 
Martinez \emph{et al.}\cite{hohenstein_thc1, hohenstein_thc2, hohenstein_thc3}
The THC is a decomposition of fourth order tensors of the form:
\begin{equation}
\begin{split} V_{pqrs} & = \sum_{\alpha \beta} W^{1}_{p,\alpha} W^{2}_{q, 
\alpha}
X_{\alpha, \beta} W^{3}_{r, \beta} W^{4}_{s, \beta} 
\end{split}
\label{eq:thc_definition}
\end{equation}
Diagrammatically, THC is
\begin{equation}
\vcenter{\hbox{\includegraphics[width=0.5\textwidth]{figures/thc_decomposition}}
}
.\label{fig:thc_decomposition}
\end{equation}
THC can be seen as a further approximation to RI, which is apparent from the 
following sequence of diagrams:
\begin{equation}
\vcenter{\hbox{\includegraphics[width=0.8\textwidth]{figures/thc_cpd}}
}
.\label{fig:thc_cpd}
\end{equation}
 As those diagrams suggest, THC can be calculated in two steps: first, RI of 
the original tensor is calculated, and then CP decomposition of the three index 
tensors is obtained by means of the 
optimization algorithms.\cite{hohenstein_thc1}

For the specific case of two electron integrals Martinez \emph{et al.} developed 
fast non-iterative methods where fixed real-space quadratures were used in 
place of factors $W^{1}, W^{2}, W^{3}, W^{4}$.\cite{hohenstein_thc3, 
hohenstein_cc2, parrish2013discrete} This can be compared to obtaining CPD 
analytically, as was mentioned in the previous section.

We proposed direct optimization methods for calculating THC using 
alternating least squares and gradient descent in 
our work,\cite{schutski2017tensor} but found them inferior to the two step 
approach originally described by Martinez \emph{et al.}.\cite{hohenstein_thc1}

\subsection{Alternating Least Squares}
Let us now describe a general optimization method, which can be applied to 
calculate several tensor decompositions. We will show its derivation for the 
optimization of THC as was done in our original work,\cite{schutski2017tensor} 
but it can be equally used to compute CPD and, possibly, other decompositions.

We define an approximation to a four index tensor $V$ by its THC 
decomposition $\tilde{V}$
%
\begin{subequations}
\begin{align} \tilde{V}_{ijkl} &= \sum_{\alpha \beta} W^{1}_{p,\alpha} W^{2}_{q, 
\alpha} X_{\alpha, \beta} W^{3}_{r, \beta} W^{4}_{s, \beta} \\
\end{align}
\end{subequations}
%
The element-wise error can be written as
%
\begin{equation}
\Delta_{V} = V - \tilde{V},
\end{equation}
%
the square of the Frobenius norm of this tensor is a sum of its entries squared:
%
\begin{equation} f = \|\Delta_V\|^2 = \sum_{pqrs} \left(V^\ast_{pqrs} -
\tilde{V}^\ast_{pqrs}\right) \, \left(V_{pqrs} -
\tilde{V}_{pqrs}\right).
\label{eq:cost_function}
\end{equation}
%
Diagrammatically, this is
%
\begin{equation}
\vcenter{\hbox{\includegraphics[height=38mm]{figures/cost_function}}}.
\label{fig:cost_function}
\end{equation}
%
where we denoted conjugated tensors by darker color. Clearly, the best possible 
THC approximation to $V$ will correspond to a minimum of the cost function $f$. 
Since $f$ is a real-valued analytic function, its derivatives with respect to 
possibly complex factors $W \in \{W^1, W^2, W^3, W^4, X\}$ are related by
$\frac{\partial f}{\partial W} = (\frac{\partial f}{\partial W^{\ast}})^{\ast}$.

In order to minimize the cost function, we proceed with the
calculation of its gradient, which can be easily done using
diagram~\ref{fig:cost_function}.  The partial derivative of $f$ with
respect to $W^1$ is
%
\begin{equation}
\vcenter{
\hbox{
\includegraphics[width=0.8\textwidth]{figures/cost_function_dfdw1}}}
\label{fig:cost_function_partial}
\end{equation}
%
Likewise, partial derivatives of $f$ with respect to other factors are 
expressed by similar diagrams with those factors removed. Using the fact that 
$\frac{\partial f}{\partial W}$ is linear in $W^\ast$, we can contract all 
factors around $W^\ast$ into an environment matrix $A$, as shown in 
diagram~\ref{fig:least_squares_w1}, and set this derivative to zero:
%
\begin{equation}
\vcenter{\hbox{\includegraphics[width=0.6\textwidth]{figures/least_squares_w1}}}
\label{fig:least_squares_w1}
\end{equation}
%
We end up with a problem
%
\begin{equation}
A \cdot W^\ast = B.
\label{eq:least_squares_w1}
\end{equation}
%
The solution to Eq.~\ref{eq:least_squares_w1} can be
obtained by multiplying from the left by the inverse of $A$ (or a 
pseudoinverse, if $A$ is a rank-deficient matrix).  Finally, we arrive to an 
expression for ${W^{1}}^{\ast}$, which diagrammatrically is
%
\begin{equation}
\vcenter{
\hbox{
\includegraphics[width=0.4\textwidth]{figures/least_squares_w1_sol}}} .
\label{fig:least_squares_w1_sol}
\end{equation}
%
Let us estimate the cost of this procedure. We call the size of the 
auxiliary indices $\alpha, \alpha^{\prime}$ the rank of the THC 
decomposition ($r_\mathrm{THC}$). The construction of the environment 
matrix $A$ scales as $O(r_\mathrm{THC}^3)$, as does computing its generalized 
inverse. If each of the dimensions of $V$ equals $N$, then the cost of 
calculating ${W^1}^{\ast}$ scales as $O(N^4 \, r_\mathrm{THC})$. Updates for the
rest of the terms in the THC decomposition can be calculated similarly.

A simple iterative optimization algorithm can be built as follows.
First, the THC factors $W$ are initialized randomly.  For each factor,
an update is calculated as shown on diagram~\ref{fig:least_squares_w1_sol}, 
keeping the other factors fixed.  The process is iterated until convergence of 
the factors. We note that this procedure is, in fact, very similar to 
partial gradient descent and the Gauss-Siedel method.\cite{yoon1988lower} The 
resulting THC-ALS algorithm is listed below.

\begin{algorithm}[H]
  \caption{Alternating Least Squares}\label{code:thc_als}
  \begin{algorithmic}[1] 
  \Function{thc-als}{$V, r_\mathrm{THC}, \epsilon$}
  \State $I_{1},I_{2},I_{3},I_{4} \gets$ size($V$)
  \State $W^1, W^2, W^3, W^4, X \gets$ init\_random($I_{1}, I_{2}, I_{3}, 
I_{4}, r_\mathrm{THC}$) 
  \Repeat \ForAll {$W \in \{W^1, W^2, W^3, W^4,
X\}$}
  \State $A_{W} \gets $ get\_environment($W^1, W^2, W^3, W^4, X$)
  \LineComment{$O(r_\mathrm{THC}^3)$}
  \State $B_{W} \gets $ get\_rhs($V,
   W^1, W^2, W^3, W^4, X$) \LineComment{$O(N^4 \, r_\mathrm{THC})$ or
$O(N^2 \, r_\mathrm{RI} \, r_\mathrm{THC})$ with RI}
   \State $W_{new} \gets A^{-1} B$\Comment{$O(r_\mathrm{THC}^3)$}
   \EndFor
   \State $\Delta \gets \max_{W} \frac{\| W_{new} - W \|}{\|
W \|}$
   \State $W \gets W_{new}$ 
   \Until $\Delta > \epsilon$ 
   
   \Return $W^1, W^2, W^3, W^4, X$
    \EndFunction
  \end{algorithmic}
\end{algorithm}
%
The calculation of the right hand side of
Eq.~\ref{eq:least_squares_w1} dominates in the cost of THC-ALS,
scaling as $O(N^4 \, r_\mathrm{THC})$. A simple modification is
possible to reduce the cost of this step by one order of magnitude. If an
RI approximation to the original tensor $V$ is available from the beginning, as 
in the case of electron interaction, it can be used in place of $V$, leading to 
a faster algorithm. The diagram corresponding to 
Eq.~\ref{eq:least_squares_w1} then becomes
%
\begin{equation}
%\vcenter{\hbox{\includegraphics[height=20mm]{figures/least_squares_w1_sol_ri}}}
\label{fig:least_squares_w1_sol_ri}
\end{equation}
%
The cost of the expression above scales as $O(N^2 \,
r_\mathrm{RI} \, r_\mathrm{THC})$, because the contraction of a
fourth-index tensor $V$ with matrices $W$ is replaced by contractions
of two third-index tensors $U$ and $\tilde{U}$. We only need to
modify the function $get\_rhs()$ to build a lower scaling algorithm,
which we refer to as THC-ALS-RI.

Alternating least squares algorithms are simple and 
often robust,\cite{uschmajew2012local} but may take a large number of
iterations to converge.\cite{comon2009tensor} Particularly, we found that 
calculating THC decomposition with ALS directly is inferior than using a two 
step scheme mentioned earlier.\cite{schutski2017tensor} Nevertheless, ALS 
procedure can be derived for various decompositions, and is a cornerstone of 
our tensor structured Coupled Cluster.

\section{Tensor Structured Coupled Cluster}
The ALS algorithm can be merged together with CC equations, leading 
CC expressions with significantly lower computational cost, which are the main 
achievement of our work.\cite{schutski2017tensor} The logic of deriving those 
novel approaches follows the same route as in case of ALS method. Here, 
we will use coupled cluster doubles (for which one neglects ${}^1\hat{T}$) as as 
example, and THC decomposition of all four index tensors. This scheme, 
however, is quite general, and we applied it to other decopositions and 
coupled cluster methods, which is discussed in subsequent sections. 

Let us impose the THC structure on the doubles amplitudes. We
approximate the amplitude tensor ${}^{2}T$ with its THC decomposition
${}^{2}\tilde{T}$ having rank $r_{T}$.  The difference between original and 
approximated
amplitudes is
%
\begin{equation} 
\Delta_{T} = {}^{2}T - {}^{2}\tilde{T} = {}^{2}T -
(Y^{2} \odot Y^{1}) \cdot Z \cdot (Y^{4} \odot Y^{3})^{T},
\end{equation}
%
where $Y^{i}$ and $Z$ are factor matrices in the THC
decomposition of ${}^{2}T$. As in case of ALS algorithm, we wish to minimize 
the squared norm of the error tensor $\Delta_{T}$, which is the minimization of 
the corresponding cost function $f_{T}$,
%
\begin{equation}
f_{T} = |\Delta_{T}|^2 = ({}^{2}T^{\ast} -
{}^{2}\tilde{T}^{\ast})({}^{2}T - {}^{2}\tilde{T}).
\end{equation}
%
Setting partial derivatives of $f_{T}$ with respect to
the decomposition factors to zero, we obtain a new set of equations
%
\begin{equation} 
\frac{\partial f_{T}}{\partial Y} = - {}^{2}T^{\ast}
\frac{\partial {}^{2} \tilde{T}}{\partial Y} + {}^{2}\tilde{T}^{\ast}
\frac{\partial {}^{2} \tilde{T}}{\partial Y} = 0,
\label{eq:cc_cost_function}
\end{equation}
%
where $Y \in \{Y^{1}, Y^{2}, Y^{3}, Y^{4}, Z\}$. Again,
as $f_{T}$ is real and analytic, only one set of derivatives (either
with respect to $Y$ or $Y^{\ast}$) is sufficient to find its minimum.

The amplitude equation in CCD method is:
\begin{equation}
{}^{2}T = {}^{2}D ~ {}^{2}G({}^{2}T), 
\label{eq:ccd_amplitude_equation_short}
\end{equation}

We proceed by replacing ${}^2T^\ast$ in Eqn.~\ref{eq:cc_cost_function} with 
${}^2D \, {}^2G$ from Eqn.~\ref{eq:ccd_amplitude_equation_short}. Effectively, 
this corresponds to minimizing the difference between a decomposed tensor 
${}^2\tilde{T}$ and a solution of the CCD amplitude equations. The resulting
amplitude equations are:
%
\begin{equation}
\tilde{T}^{\ast} \frac{\partial \tilde{T}}{\partial
Y} = {}^{2}G {}^{2}D \frac{\partial \tilde{T}}{\partial Y}.
\end{equation}
%
This is the analogue of Eq.~\ref{eq:least_squares_w1}
in THC-ALS, and can be solved with the help of the pseudoinverse as the 
left-hand-side is linear in $Y^\ast$.  Diagrammatically, we have
%
\begin{equation}
\vcenter{\hbox{\includegraphics[width=0.6\textwidth]{figures/cc_thc}}}.
\label{fig:cc_thc}
\end{equation}
%
Note that the energy denominator ${}^2D$ is represented 
here as an order-8 diagonal tensor ${}^2D^{aba^{\prime} b^{\prime}}_{ij 
i^{\prime} j^{\prime}}$, instead of an order-4 dense tensor ${}^2D^{ab}_{ij}$ 
as in Eq.~\ref{eq:ccd_amplitude_equation}. The final form of our ALS-type 
coupled cluster doubles equations is provided below (an example for the factor 
$Y^{1}$ is shown; expressions for other factors are analogous):
%
\begin{equation}
\vcenter{\hbox{\includegraphics[width=0.4\textwidth]{figures/cc_thc_sol}}}.
\label{fig:cc_thc_als}
\end{equation}
%

Here ${}^2G$ on the right hand side is a collection of tensor contractions 
involving the Hamiltonian and THC approximated ${}^2T$ amplitudes 
(see Eqn.~\ref{eq:ccd_amplitude_equation} for the full list of these terms).
We substitute electron interaction with its THC decomposition calculated 
beforehand, for example, with ALS. The size of the auxiliary dimension in 
this decomposition is $r_{V}$, and needs to be only of order $O(N)$ for a good 
approximation, as was discussed previously in the section 
\ref{sec:tensor_hypercontraction}. We also substitute the denominator tensor by 
its CP decomposition obtained analytically by means of Laplace transformation. 
The CP rank $r_{D}$ in this decomposition is a small constant $\sim 15$ and 
does not depend on $N$. The final expressions, where all order-4 tensors are 
substituted by their decompositions, factorize. After defining proper 
intermediates, the cost of these equations has quartic scaling in $r_{V}$, 
$r_{T}$ and $N$ per iteration. An example of such factorization for the 
contraction we considered before in Eqn.~\ref{eq:ccd_intermediate_example2} is 
shown below diagrammatically (we used dashed line to show an auxiliary 
index in the CP decomposition of ${}^2 D$):
\begin{equation}
\begin{split}
\tau^{ab}_{ij} & = {}^2 T^{cd}_{ij} V^{ab}_{cd} \\
Y^{1 \ast} &\longleftarrow {}^1A^{-1} \cdot \tau \cdot {}^{2}D 
\cdot \frac{\partial ({}^2\tilde{T})}{\partial Y^{1}}
\end{split}
\end{equation}

%
\begin{equation}
\vcenter{\hbox{\includegraphics[width=0.95\textwidth]{figures/cc_thc_example}}}.
\label{fig:cc_thc_example}
\end{equation}
%
Although diagrams are convenient for explaining tensor factorizations, it 
is still quite challenging to define good intermediates even for the 
simplest decomposed CCD method. We derived factorized equations using an 
automated algebraic system developed in our group.\cite{drudge1, drudge2} We 
refer the reader to the supplementary material from 
Ref.~\cite{schutski2017tensor} for the complete listing of these expressions for 
the THC decomposed CCSD method (denoted as RCCSD-THC), as well as their 
implementation in Python.\cite{van2007python}

Equation \ref{fig:cc_thc_als}, which represents a combination of CC and ALS 
update, is a cornerstone of the tensor structured Coupled Cluster method and 
the main achievement of this work. This scheme is quite generic  
and can be applied to any factorization of amplitudes and the Hamiltonian. In 
the following sections we will discuss numerical experiments with some of those 
novel methods.

\section{RCCSD-THC method}
To test the performance of tensor structured coupled cluster, we 
tested it on a set of small to medium size molecules. We 
start with the RCCSD method, where both two body interaction part of the 
Hamiltonian and ${}^2T$ amplitues have THC structure. Diagrammatically, this is 
summarized as:
%
\begin{equation}
%\vcenter{\hbox{\includegraphics[width=0.95\textwidth]{figures/rccsd_thc_def}}.
\label{fig:rccsd_thc_def}
\end{equation}
%
As diagrams show, two electron interaction is decomposed in Mulliken order, as 
well as two body excitation amplitudes. This choice of decompositions results 
in a procedure with a quartic cost in the basis size $N$ and the ranks of THC 
decomposition.

In our setup the decomposition of the electron interaction tensor was 
calculated with a two step procedure, as described in 
Ref.~\cite{schutski2017tensor} First, partial singular value decomposition of 
the integrals in AO basis was calculated. We retained $r_{V}$ singular values 
and vectors. For larger systems, listed in Tab.~\ref{Tab:Energies}, RI 
decomposed two electron integrals were used in place of singular 
vectors. Next, a CP decomposition of rank $r_{V}$ of the resulting 
left and right singular vectors (arranged as three index tensors of size $N 
\times N \times r_{v}$) was calculated with ALS. The iterative least squares 
procedure was stopped when the ratio of the objective function $f$ to the square 
of the Frobenius norm of the original tensor dropped below $10^{-14}$, or a 
limit of 1000 iterations was reached.

The subsequent coupled cluster calculations were stopped either after the 
energy was converged to within $10^{-9}$ Hartree or a limit of 250 iterations 
was reached. All calculations used the cc-pVDZ basis from EMSL
database,\cite{schuchardt2007basis} and the corresponding cc-pVDZ-RI
was used in the RI approximation. The threshold for pseudoinverses was set to 
$10^{-10}$

\subsection{Accuracy of THC for two electron integral approximation}
The accuracy of the THC decomposition of the two-electron integrals governs the
accuracy of the energy in subsequent calculations. Thus, it is important 
wish to check the dependence on the error in the decomposition of
two-electron integrals on THC rank.
Figure~\ref{fig:thc_err_mo_3systems} plots this error in a double
logarithmic scale for three small molecules.  We note that the
decomposition is computationally useful if the rank $r_\mathrm{RHC}$
is close to the number of basis functions $N$.  As the figure shows,
the error in the two-electron integrals decays exponentially with
respect to THC rank.  We found that this trend holds for every system
tested and depends only slightly on whether the two-electron integrals
are decomposed in the atomic orbital or molecular orbital basis.

%
\begin{figure}[tb]
%\includegraphics[width=\columnwidth]{figures/thc_err_mo_3systems}
\caption{Frobenius norm of error in decomposed two electron integrals.
\label{fig:thc_err_mo_3systems}}
\end{figure}
%
To see how the decomposition affects subsequent energies, we checked
the error in the second-order M{\o}ller-Plesset (MP2) correlation
energy, as shown in Fig.~\ref{fig:mp2_err_ao_full}.  The combination
of MP2 and THC was first proposed by Hohenstein \emph{et
al}.\cite{hohenstein_thc2} and scales as $O(N^4)$.  These authors used
a version of THC with the restriction that all factors $W$ were the
same, which we did not impose in our work. 
The error in the MP2 correlation energy follows the trend seen in the
decomposition of the two-electron integrals.  Results within $0.1~mH$
of the exact MP2 correlation energy are already achieved with
$r_\mathrm{THC} \sim N^{1.2} - N^{1.4}$.  We expect that the THC would
work better for larger and more extended systems as the two-electron
integrals become sparser and a lower rank decomposition would
correspondingly become more accurate.
%
\begin{figure}[tb]
%\includegraphics[width=\columnwidth]{figures/mp2_err_ao_full}
\caption{Absolute error in the MP2 correlation energy.
\label{fig:mp2_err_ao_full}}
\end{figure}
%

\section{Appendix}
\label{sec:Appendix} 